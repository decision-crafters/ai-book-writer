# AI Book Writer LLM Configuration
# Copy this file to .env and fill in the required values

# ========================
# Model Selection
# ========================

# Available models:
# - mistral-nemo-instruct-2407 (local)
# - openai/gpt-4, openai/gpt-3.5-turbo
# - deepseek/deepseek-chat
# - gemini/gemini-pro
# - groq/llama2-70b-4096
# - gemini-flash/gemini-flash

# Selected model (must match one of the above formats)
LLM_MODEL=openai/gpt-4

# ========================
# API Keys
# ========================

# OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here

# DeepSeek API key
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Gemini API key
GEMINI_API_KEY=your_gemini_api_key_here

# Groq API key
GROQ_API_KEY=your_groq_api_key_here

# O1 API key
O1_API_KEY=your_o1_api_key_here

# O1 Model Configuration
O1_MODEL=o1  # Options: o1, o1-mini
O1_MAX_TOKENS=100000  # Maximum output tokens (including reasoning)
O1_TIMEOUT=300  # Timeout in seconds (5 minutes)

# Gemini Flash API key
GEMINI_FLASH_API_KEY=your_gemini_flash_api_key_here

# ========================
# Local Model Configuration
# ========================

# Base URL for local Mistral-Nemo model
MISTRAL_NEMO_BASE_URL=http://localhost:1234/v1

# ========================
# Connection Testing
# ========================

# Enable connection testing on startup (true/false)
TEST_CONNECTION=true

# Connection timeout in seconds
CONNECTION_TIMEOUT=30
